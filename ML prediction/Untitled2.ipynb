{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9WoO0Qd4LB_-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import joblib # For saving/loading model components\n",
        "import os\n",
        "import re # For basic text cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COURSERA_DATA_PATH = '/content/Coursera.csv'"
      ],
      "metadata": {
        "id": "Q-YPqLEDLgnT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = 'course_recommender_model' # Directory to save model files\n",
        "VECTORIZER_PATH = os.path.join(MODEL_DIR, 'tfidf_vectorizer.joblib')\n",
        "COURSE_MATRIX_PATH = os.path.join(MODEL_DIR, 'course_tfidf_matrix.joblib')\n",
        "COURSE_METADATA_PATH = os.path.join(MODEL_DIR, 'course_metadata.joblib')"
      ],
      "metadata": {
        "id": "vbdsPOw-Lu0_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n",
        "    return text"
      ],
      "metadata": {
        "id": "VdNc1Dn-LvO6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(file_path):\n",
        "    print(f\"Loading data from {file_path}...\")\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Dataset file not found at {file_path}\")\n",
        "        print(\"Please download 'Coursera_courses.csv' from Kaggle and place it in the correct path.\")\n",
        "        return None\n",
        "\n",
        "    # Select relevant columns and handle missing values\n",
        "    # Renaming for easier access\n",
        "    df = df.rename(columns={\n",
        "        'Course Name': 'course_title',\n",
        "        'Course Description': 'course_description',\n",
        "        'Skills': 'course_skills'\n",
        "    })\n",
        "\n",
        "    # Ensure essential columns exist\n",
        "    required_cols = ['course_title', 'course_description', 'course_skills', 'Course URL']\n",
        "    for col in required_cols:\n",
        "        if col not in df.columns:\n",
        "            print(f\"Error: Required column '{col}' not found in the dataset.\")\n",
        "            return None\n",
        "\n",
        "    df['course_description'] = df['course_description'].fillna('')\n",
        "    df['course_skills'] = df['course_skills'].fillna('')\n",
        "    df['course_title'] = df['course_title'].fillna('') # Title is crucial\n",
        "\n",
        "    # Drop rows where title is empty after fillna (shouldn't happen if CSV is good)\n",
        "    df.dropna(subset=['course_title'], inplace=True)\n",
        "    df = df[df['course_title'].str.strip() != '']\n",
        "\n",
        "\n",
        "    # Combine text features for TF-IDF\n",
        "    # Giving skills a bit more prominence by repeating them (optional heuristic)\n",
        "    df['combined_features'] = df['course_title'].apply(clean_text) + ' ' + \\\n",
        "                              df['course_description'].apply(clean_text) + ' ' + \\\n",
        "                              (df['course_skills'].apply(clean_text) + ' ') * 2 # Repeat skills\n",
        "\n",
        "    # Drop duplicates based on title and description (or URL if more robust)\n",
        "    df.drop_duplicates(subset=['course_title', 'course_description'], inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    print(f\"Data loaded and preprocessed. Shape: {df.shape}\")\n",
        "    return df[['course_title', 'Course URL', 'combined_features', 'course_skills', 'course_description']]\n"
      ],
      "metadata": {
        "id": "pRkQinWyLy-U"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_components():\n",
        "    print(\"Loading model components...\")\n",
        "    if not all([os.path.exists(p) for p in [VECTORIZER_PATH, COURSE_MATRIX_PATH, COURSE_METADATA_PATH]]):\n",
        "        print(\"Model components not found. Please train the model first.\")\n",
        "        return None, None, None\n",
        "\n",
        "    vectorizer = joblib.load(VECTORIZER_PATH)\n",
        "    course_matrix = joblib.load(COURSE_MATRIX_PATH)\n",
        "    course_metadata = joblib.load(COURSE_METADATA_PATH)\n",
        "    print(\"Model components loaded successfully.\")\n",
        "    return vectorizer, course_matrix, course_metadata"
      ],
      "metadata": {
        "id": "DnTWiz0IL9iR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_course_recommendations(job_title, job_description, top_n=3):\n",
        "    vectorizer, course_matrix, course_metadata = load_model_components()\n",
        "\n",
        "    if vectorizer is None:\n",
        "        print(\"Model not loaded. Cannot provide recommendations.\")\n",
        "        return []\n",
        "\n",
        "    # Combine job title and description to form the query\n",
        "    query_text = clean_text(job_title + \" \" + job_description)\n",
        "    if not query_text.strip():\n",
        "        print(\"Query text is empty after cleaning. Cannot make recommendations.\")\n",
        "        return []\n",
        "\n",
        "    # Transform the query using the loaded vectorizer\n",
        "    query_vector = vectorizer.transform([query_text])\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    cosine_similarities = cosine_similarity(query_vector, course_matrix).flatten()\n",
        "\n",
        "    # Get indices of top_n most similar courses\n",
        "    # argsort returns indices that would sort the array. We take the last 'top_n' in reverse.\n",
        "    related_courses_indices = cosine_similarities.argsort()[-top_n:][::-1]\n",
        "\n",
        "    recommendations = []\n",
        "    print(f\"\\nTop {top_n} course recommendations for '{job_title}':\")\n",
        "    for i, index in enumerate(related_courses_indices):\n",
        "        similarity_score = cosine_similarities[index]\n",
        "        if similarity_score > 0.01 : # Only recommend if there's some minimal similarity\n",
        "            course_info = course_metadata.iloc[index]\n",
        "            recommendations.append({\n",
        "                \"title\": course_info['course_title'],\n",
        "                \"url\": course_info['Course URL'],\n",
        "                \"similarity\": similarity_score,\n",
        "                \"description\": course_info['course_description'][:200] + \"...\" if course_info['course_description'] else \"N/A\", # Snippet\n",
        "                \"skills\": course_info['course_skills'] if course_info['course_skills'] else \"N/A\"\n",
        "            })\n",
        "            print(f\"  {i+1}. {course_info['course_title']} (Similarity: {similarity_score:.4f})\")\n",
        "            print(f\"      URL: {course_info['Course URL']}\")\n",
        "            # print(f\"      Skills: {course_info['course_skills']}\")\n",
        "\n",
        "    if not recommendations:\n",
        "        print(\"No suitable courses found matching the criteria.\")\n",
        "\n",
        "    return recommendations\n"
      ],
      "metadata": {
        "id": "NRRcEWLaMImO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(df):\n",
        "    if df is None or df.empty:\n",
        "        print(\"Cannot train model: DataFrame is empty or None.\")\n",
        "        return None, None, None\n",
        "\n",
        "    print(\"Training TF-IDF vectorizer...\")\n",
        "    # Using stop_words='english' and ngram_range for better feature capture\n",
        "    # min_df=2: ignore terms that appear in less than 2 documents\n",
        "    # max_df=0.8: ignore terms that appear in more than 80% of documents (too common)\n",
        "    tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), min_df=2, max_df=0.8)\n",
        "\n",
        "    # Fit and transform the combined features\n",
        "    course_tfidf_matrix = tfidf_vectorizer.fit_transform(df['combined_features'])\n",
        "    print(f\"TF-IDF matrix shape: {course_tfidf_matrix.shape}\")\n",
        "\n",
        "    # Save the components\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    joblib.dump(tfidf_vectorizer, VECTORIZER_PATH)\n",
        "    joblib.dump(course_tfidf_matrix, COURSE_MATRIX_PATH)\n",
        "    joblib.dump(df[['course_title', 'Course URL', 'course_skills', 'course_description']], COURSE_METADATA_PATH) # Save metadata for recommendations\n",
        "\n",
        "    print(f\"Model components saved to {MODEL_DIR}/\")\n",
        "    return tfidf_vectorizer, course_tfidf_matrix, df[['course_title', 'Course URL', 'course_skills', 'course_description']]\n"
      ],
      "metadata": {
        "id": "gWb5WiAJMr-0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # --- Step 1: (One-time or periodic) Training ---\n",
        "    # Check if model components exist, if not, train and save.\n",
        "    if not all([os.path.exists(p) for p in [VECTORIZER_PATH, COURSE_MATRIX_PATH, COURSE_METADATA_PATH]]):\n",
        "        print(\"Model components not found. Training new model...\")\n",
        "        coursera_df = load_and_preprocess_data(COURSERA_DATA_PATH)\n",
        "        if coursera_df is not None and not coursera_df.empty:\n",
        "            train_model(coursera_df)\n",
        "        else:\n",
        "            print(\"Failed to load data. Exiting.\")\n",
        "            exit()\n",
        "    else:\n",
        "        print(\"Found existing model components. Loading them for prediction.\")\n",
        "\n",
        "    # --- Step 2: (For each prediction request) Getting Recommendations ---\n",
        "    sample_job_title = \"Data Scientist\"\n",
        "    sample_job_description = \"\"\"\n",
        "    We are looking for a Data Scientist to analyze large amounts of raw information\n",
        "    to find patterns that will help improve our company. We will rely on you to build\n",
        "    data products to extract valuable business insights. In this role, you should be\n",
        "    highly analytical with a knack for analysis, math, and statistics. Critical thinking\n",
        "    and problem-solving skills are essential for interpreting data. We want to see a passion\n",
        "    for machine-learning and research. Your goal will be to help our company analyze trends\n",
        "    to make better decisions. Responsibilities include undertaking data collection,\n",
        "    preprocessing and analysis, building models to address business problems, and presenting\n",
        "    information using data visualization techniques. Skills in Python, R, SQL, and machine learning are required.\n",
        "    Familiarity with data frameworks like Spark or Hadoop is a plus.\n",
        "    \"\"\"\n",
        "\n",
        "    recommendations = get_course_recommendations(sample_job_title, sample_job_description, top_n=3)\n",
        "\n",
        "    # Example of how you might use the output\n",
        "    if recommendations:\n",
        "        print(\"\\n--- Formatted Recommendations ---\")\n",
        "        for rec in recommendations:\n",
        "            print(f\"Title: {rec['title']}\\nURL: {rec['url']}\\nSimilarity: {rec['similarity']:.4f}\\n\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihh7sZG_MO_I",
        "outputId": "f905af72-90a1-4e10-a078-57c359fcf993"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model components not found. Training new model...\n",
            "Loading data from /content/Coursera.csv...\n",
            "Data loaded and preprocessed. Shape: (3424, 8)\n",
            "Training TF-IDF vectorizer...\n",
            "TF-IDF matrix shape: (3424, 55862)\n",
            "Model components saved to course_recommender_model/\n",
            "Loading model components...\n",
            "Model components loaded successfully.\n",
            "\n",
            "Top 3 course recommendations for 'Data Scientist':\n",
            "  1. SQL for Data Science (Similarity: 0.2660)\n",
            "      URL: https://www.coursera.org/learn/sql-for-data-science\n",
            "  2. Data Visualization with Python (Similarity: 0.2233)\n",
            "      URL: https://www.coursera.org/learn/python-for-data-visualization\n",
            "  3. Introduction to Data Analytics (Similarity: 0.2123)\n",
            "      URL: https://www.coursera.org/learn/introduction-to-data-analytics\n",
            "\n",
            "--- Formatted Recommendations ---\n",
            "Title: SQL for Data Science\n",
            "URL: https://www.coursera.org/learn/sql-for-data-science\n",
            "Similarity: 0.2660\n",
            "\n",
            "Title: Data Visualization with Python\n",
            "URL: https://www.coursera.org/learn/python-for-data-visualization\n",
            "Similarity: 0.2233\n",
            "\n",
            "Title: Introduction to Data Analytics\n",
            "URL: https://www.coursera.org/learn/introduction-to-data-analytics\n",
            "Similarity: 0.2123\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "khrFyUMzMZHu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}